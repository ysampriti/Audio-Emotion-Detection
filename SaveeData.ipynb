{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"./Savee/DC\"\n",
    "path2 = \"./Savee/JE\"\n",
    "path3 = \"./Savee/JK\"\n",
    "path4 = \"./Savee/KL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_speaker1 = os.listdir(path1)\n",
    "directory_speaker2 = os.listdir(path2)\n",
    "directory_speaker3 = os.listdir(path3)\n",
    "directory_speaker4 = os.listdir(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['su13.wav',\n",
       " 'n25.wav',\n",
       " 'su05.wav',\n",
       " 'h14.wav',\n",
       " 'n17.wav',\n",
       " 'd13.wav',\n",
       " 'sa12.wav',\n",
       " 'su11.wav',\n",
       " 'n02.wav',\n",
       " 'd02.wav',\n",
       " 'd03.wav',\n",
       " 'su04.wav',\n",
       " 'f11.wav',\n",
       " 'su02.wav',\n",
       " 'a02.wav',\n",
       " 'h03.wav',\n",
       " 'su10.wav',\n",
       " 'n07.wav',\n",
       " 'h05.wav',\n",
       " 'd07.wav',\n",
       " 'h07.wav',\n",
       " 'f12.wav',\n",
       " 'n24.wav',\n",
       " 'd01.wav',\n",
       " 'a05.wav',\n",
       " 'd12.wav',\n",
       " 'n09.wav',\n",
       " 'a12.wav',\n",
       " 'h10.wav',\n",
       " 'd06.wav',\n",
       " 'n01.wav',\n",
       " 'd05.wav',\n",
       " 'f10.wav',\n",
       " 'h01.wav',\n",
       " 'a10.wav',\n",
       " 'sa11.wav',\n",
       " 'n23.wav',\n",
       " 'h04.wav',\n",
       " 'sa08.wav',\n",
       " 'n14.wav',\n",
       " 'd10.wav',\n",
       " 'h11.wav',\n",
       " 'f14.wav',\n",
       " 'f03.wav',\n",
       " 'n11.wav',\n",
       " 'f04.wav',\n",
       " 'a04.wav',\n",
       " 'su01.wav',\n",
       " 'n29.wav',\n",
       " 'a01.wav',\n",
       " 'd08.wav',\n",
       " 'n15.wav',\n",
       " 'sa15.wav',\n",
       " 'd04.wav',\n",
       " 'a03.wav',\n",
       " 'h08.wav',\n",
       " 'n19.wav',\n",
       " 'n18.wav',\n",
       " 'sa01.wav',\n",
       " 'n03.wav',\n",
       " 'n08.wav',\n",
       " 'a13.wav',\n",
       " 'n27.wav',\n",
       " 'n28.wav',\n",
       " 'a07.wav',\n",
       " 'a09.wav',\n",
       " 'n10.wav',\n",
       " 'su15.wav',\n",
       " 'sa03.wav',\n",
       " 'sa07.wav',\n",
       " 'a08.wav',\n",
       " 'sa14.wav',\n",
       " 'su08.wav',\n",
       " 'n12.wav',\n",
       " 'd15.wav',\n",
       " 'n05.wav',\n",
       " 'su07.wav',\n",
       " 'n16.wav',\n",
       " 'h13.wav',\n",
       " 'f08.wav',\n",
       " 'n06.wav',\n",
       " 'sa06.wav',\n",
       " 'h12.wav',\n",
       " 'sa09.wav',\n",
       " 'n20.wav',\n",
       " 'f06.wav',\n",
       " 'su03.wav',\n",
       " 'a14.wav',\n",
       " 'f07.wav',\n",
       " 'su12.wav',\n",
       " 'f13.wav',\n",
       " 'sa10.wav',\n",
       " 'd09.wav',\n",
       " 'su09.wav',\n",
       " 'h06.wav',\n",
       " 'n26.wav',\n",
       " 'h09.wav',\n",
       " 'n30.wav',\n",
       " 'f02.wav',\n",
       " 'f15.wav',\n",
       " 'f09.wav',\n",
       " 'sa13.wav',\n",
       " 'f05.wav',\n",
       " 'f01.wav',\n",
       " 'd14.wav',\n",
       " 'n13.wav',\n",
       " 'su06.wav',\n",
       " 'n22.wav',\n",
       " 'sa02.wav',\n",
       " 'd11.wav',\n",
       " 'n21.wav',\n",
       " 'a15.wav',\n",
       " 'sa05.wav',\n",
       " 'h15.wav',\n",
       " 'sa04.wav',\n",
       " 'a06.wav',\n",
       " 'a11.wav',\n",
       " 'h02.wav',\n",
       " 'n04.wav',\n",
       " 'su14.wav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_speaker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in directory_speaker1:\n",
    "#     if label[0]=='a':\n",
    "#         Y.append(0)\n",
    "#     elif label[0]=='d':\n",
    "#         Y.append(1)\n",
    "#     elif label[0]=='f':\n",
    "#         Y.append(2)\n",
    "#     elif label[0]=='h':\n",
    "#         Y.append(3)\n",
    "#     elif label[0]=='n':\n",
    "#         Y.append(4)\n",
    "#     elif label[0]=='s' and label[1]=='a':\n",
    "#         Y.append(5)\n",
    "#     else:\n",
    "#         Y.append(6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in directory_speaker2:\n",
    "#     if label[0]=='a':\n",
    "#         Y.append(0)\n",
    "#     elif label[0]=='d':\n",
    "#         Y.append(1)\n",
    "#     elif label[0]=='f':\n",
    "#         Y.append(2)\n",
    "#     elif label[0]=='h':\n",
    "#         Y.append(3)\n",
    "#     elif label[0]=='n':\n",
    "#         Y.append(4)\n",
    "#     elif label[0]=='s' and label[1]=='a':\n",
    "#         Y.append(5)\n",
    "#     else:\n",
    "#         Y.append(6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in directory_speaker3:\n",
    "#     if label[0]=='a':\n",
    "#         Y.append(0)\n",
    "#     elif label[0]=='d':\n",
    "#         Y.append(1)\n",
    "#     elif label[0]=='f':\n",
    "#         Y.append(2)\n",
    "#     elif label[0]=='h':\n",
    "#         Y.append(3)\n",
    "#     elif label[0]=='n':\n",
    "#         Y.append(4)\n",
    "#     elif label[0]=='s' and label[1]=='a':\n",
    "#         Y.append(5)\n",
    "#     else:\n",
    "#         Y.append(6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in directory_speaker4:\n",
    "#     if label[0]=='a':\n",
    "#         Y.append(0)\n",
    "#     elif label[0]=='d':\n",
    "#         Y.append(1)\n",
    "#     elif label[0]=='f':\n",
    "#         Y.append(2)\n",
    "#     elif label[0]=='h':\n",
    "#         Y.append(3)\n",
    "#     elif label[0]=='n':\n",
    "#         Y.append(4)\n",
    "#     elif label[0]=='s' and label[1]=='a':\n",
    "#         Y.append(5)\n",
    "#     else:\n",
    "#         Y.append(6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    0 : \"angry\",\n",
    "    1 : \"disgust\",\n",
    "    2 : \"fear\",\n",
    "    3 : \"happy\",\n",
    "    4 : \"neutral\",\n",
    "    5 : \"sad\",\n",
    "    6 : \"surprised\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audios = []\n",
    "# srs = []\n",
    "# z = 0\n",
    "# for name in directory_speaker1:\n",
    "#     file = path1 +'/'+ name\n",
    "#     z+=1\n",
    "# #     if z%15==0:\n",
    "# #         print(file)\n",
    "#     x,sr = librosa.load(file)\n",
    "#     audios.append(x)\n",
    "#     srs.append(sr)\n",
    "# #     print(sr)\n",
    "\n",
    "\n",
    "# for name in directory_speaker2:\n",
    "#     file = path2 +'/'+ name\n",
    "#     z+=1\n",
    "# #     if z%15==0:\n",
    "# #         print(file)\n",
    "#     x,sr = librosa.load(file)\n",
    "#     audios.append(x)\n",
    "#     srs.append(sr)\n",
    "    \n",
    "    \n",
    "\n",
    "# for name in directory_speaker3:\n",
    "#     file = path3 +'/'+ name\n",
    "#     z+=1\n",
    "# #     if z%15==0:\n",
    "# #         print(file)\n",
    "#     x,sr = librosa.load(file)\n",
    "#     audios.append(x)\n",
    "#     srs.append(sr)\n",
    "    \n",
    "    \n",
    "# for name in directory_speaker4:\n",
    "#     file = path4 +'/'+ name\n",
    "#     z+=1\n",
    "# #     if z%15==0:\n",
    "# #         print(file)\n",
    "#     x,sr = librosa.load(file)\n",
    "#     audios.append(x)\n",
    "#     srs.append(sr)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5a815e99b4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'audios' is not defined"
     ]
    }
   ],
   "source": [
    "len(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Savee_audios.npy', audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Savee_labels.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = np.load('Savee_audios.npy', allow_pickle=True)\n",
    "Y = np.load('Savee_labels.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(audio, mfcc, chroma, mel):\n",
    "    X = audio\n",
    "    sample_rate = 22050\n",
    "    if chroma:\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "    if mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    X_new,Y_new=[],[]\n",
    "    idx = 0;\n",
    "    for audio in audios:\n",
    "        emotion = emotion_dict[Y[idx]]\n",
    "        print(emotion)\n",
    "        idx +=1\n",
    "#         if emotion not in observed_emotions:\n",
    "#             continue\n",
    "\n",
    "        feature=extract_feature(audio, mfcc=True, chroma=True, mel=True)\n",
    "        X_new.append(feature)\n",
    "        Y_new.append(emotion)\n",
    "        \n",
    "    return (X_new,Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprised\n",
      "neutral\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "disgust\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "disgust\n",
      "surprised\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "happy\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "disgust\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "happy\n",
      "disgust\n",
      "neutral\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "angry\n",
      "sad\n",
      "neutral\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "fear\n",
      "neutral\n",
      "fear\n",
      "angry\n",
      "surprised\n",
      "neutral\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "angry\n",
      "neutral\n",
      "surprised\n",
      "sad\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "fear\n",
      "surprised\n",
      "fear\n",
      "sad\n",
      "disgust\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "neutral\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "surprised\n",
      "surprised\n",
      "neutral\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "disgust\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "disgust\n",
      "surprised\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "happy\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "disgust\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "happy\n",
      "disgust\n",
      "neutral\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "angry\n",
      "sad\n",
      "neutral\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "fear\n",
      "neutral\n",
      "fear\n",
      "angry\n",
      "surprised\n",
      "neutral\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "angry\n",
      "neutral\n",
      "surprised\n",
      "sad\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "fear\n",
      "surprised\n",
      "fear\n",
      "sad\n",
      "disgust\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "neutral\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "surprised\n",
      "surprised\n",
      "neutral\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "disgust\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "disgust\n",
      "surprised\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "happy\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "disgust\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "happy\n",
      "disgust\n",
      "neutral\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "angry\n",
      "sad\n",
      "neutral\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "fear\n",
      "neutral\n",
      "fear\n",
      "angry\n",
      "surprised\n",
      "neutral\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "angry\n",
      "neutral\n",
      "surprised\n",
      "sad\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "fear\n",
      "surprised\n",
      "fear\n",
      "sad\n",
      "disgust\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "neutral\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "surprised\n",
      "surprised\n",
      "neutral\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "disgust\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "disgust\n",
      "surprised\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "happy\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "disgust\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "happy\n",
      "disgust\n",
      "neutral\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "angry\n",
      "sad\n",
      "neutral\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "disgust\n",
      "happy\n",
      "fear\n",
      "fear\n",
      "neutral\n",
      "fear\n",
      "angry\n",
      "surprised\n",
      "neutral\n",
      "angry\n",
      "disgust\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "angry\n",
      "neutral\n",
      "surprised\n",
      "sad\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "surprised\n",
      "neutral\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "happy\n",
      "fear\n",
      "neutral\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "neutral\n",
      "fear\n",
      "surprised\n",
      "angry\n",
      "fear\n",
      "surprised\n",
      "fear\n",
      "sad\n",
      "disgust\n",
      "surprised\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "neutral\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "disgust\n",
      "neutral\n",
      "surprised\n",
      "neutral\n",
      "sad\n",
      "disgust\n",
      "neutral\n",
      "angry\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "surprised\n"
     ]
    }
   ],
   "source": [
    "DATA = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, Y_new= DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 180)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(X_new)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_new = np.array(Y_new)\n",
    "Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"./Savee_X.npy\",X_new)\n",
    "# np.save(\"./Savee_Y.npy\",Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.load(\"./Savee_X.npy\")\n",
    "Y_new = np.load(\"./Savee_Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kF = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train, X_new_test, Y_new_train, Y_new_test  = train_test_split(X_new, Y_new,test_size=0.10,random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 48)\n"
     ]
    }
   ],
   "source": [
    "print((X_new_train.shape[0], X_new_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=264, epsilon=1e-08,\n",
    "                    hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=700, \n",
    "                    activation='tanh',learning_rate_init=0.001, verbose=True, early_stopping=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.00068067\n",
      "Validation score: 0.256410\n",
      "Iteration 2, loss = 2.13803848\n",
      "Validation score: 0.410256\n",
      "Iteration 3, loss = 1.79230298\n",
      "Validation score: 0.358974\n",
      "Iteration 4, loss = 1.68039154\n",
      "Validation score: 0.333333\n",
      "Iteration 5, loss = 1.58229748\n",
      "Validation score: 0.410256\n",
      "Iteration 6, loss = 1.49884103\n",
      "Validation score: 0.384615\n",
      "Iteration 7, loss = 1.43861314\n",
      "Validation score: 0.333333\n",
      "Iteration 8, loss = 1.38938732\n",
      "Validation score: 0.333333\n",
      "Iteration 9, loss = 1.33462148\n",
      "Validation score: 0.384615\n",
      "Iteration 10, loss = 1.27326085\n",
      "Validation score: 0.410256\n",
      "Iteration 11, loss = 1.22747743\n",
      "Validation score: 0.461538\n",
      "Iteration 12, loss = 1.19549046\n",
      "Validation score: 0.487179\n",
      "Iteration 13, loss = 1.16304763\n",
      "Validation score: 0.487179\n",
      "Iteration 14, loss = 1.12905800\n",
      "Validation score: 0.487179\n",
      "Iteration 15, loss = 1.09788428\n",
      "Validation score: 0.461538\n",
      "Iteration 16, loss = 1.07566430\n",
      "Validation score: 0.461538\n",
      "Iteration 17, loss = 1.05046959\n",
      "Validation score: 0.461538\n",
      "Iteration 18, loss = 1.02473225\n",
      "Validation score: 0.461538\n",
      "Iteration 19, loss = 1.00482735\n",
      "Validation score: 0.435897\n",
      "Iteration 20, loss = 0.98904981\n",
      "Validation score: 0.435897\n",
      "Iteration 21, loss = 0.96868697\n",
      "Validation score: 0.435897\n",
      "Iteration 22, loss = 0.95059375\n",
      "Validation score: 0.487179\n",
      "Iteration 23, loss = 0.93245230\n",
      "Validation score: 0.487179\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.30434769\n",
      "Validation score: 0.358974\n",
      "Iteration 2, loss = 1.83681671\n",
      "Validation score: 0.384615\n",
      "Iteration 3, loss = 1.63770587\n",
      "Validation score: 0.384615\n",
      "Iteration 4, loss = 1.51757829\n",
      "Validation score: 0.461538\n",
      "Iteration 5, loss = 1.43661990\n",
      "Validation score: 0.410256\n",
      "Iteration 6, loss = 1.38667579\n",
      "Validation score: 0.435897\n",
      "Iteration 7, loss = 1.32826317\n",
      "Validation score: 0.435897\n",
      "Iteration 8, loss = 1.27395149\n",
      "Validation score: 0.487179\n",
      "Iteration 9, loss = 1.23992795\n",
      "Validation score: 0.487179\n",
      "Iteration 10, loss = 1.21398669\n",
      "Validation score: 0.512821\n",
      "Iteration 11, loss = 1.18918501\n",
      "Validation score: 0.538462\n",
      "Iteration 12, loss = 1.15478417\n",
      "Validation score: 0.512821\n",
      "Iteration 13, loss = 1.11615794\n",
      "Validation score: 0.512821\n",
      "Iteration 14, loss = 1.08385777\n",
      "Validation score: 0.512821\n",
      "Iteration 15, loss = 1.06348104\n",
      "Validation score: 0.538462\n",
      "Iteration 16, loss = 1.04330474\n",
      "Validation score: 0.564103\n",
      "Iteration 17, loss = 1.01785996\n",
      "Validation score: 0.538462\n",
      "Iteration 18, loss = 0.99639492\n",
      "Validation score: 0.564103\n",
      "Iteration 19, loss = 0.98111512\n",
      "Validation score: 0.589744\n",
      "Iteration 20, loss = 0.96352807\n",
      "Validation score: 0.589744\n",
      "Iteration 21, loss = 0.94829872\n",
      "Validation score: 0.589744\n",
      "Iteration 22, loss = 0.93075000\n",
      "Validation score: 0.615385\n",
      "Iteration 23, loss = 0.91346680\n",
      "Validation score: 0.589744\n",
      "Iteration 24, loss = 0.89812080\n",
      "Validation score: 0.589744\n",
      "Iteration 25, loss = 0.88488807\n",
      "Validation score: 0.589744\n",
      "Iteration 26, loss = 0.87261535\n",
      "Validation score: 0.615385\n",
      "Iteration 27, loss = 0.85854188\n",
      "Validation score: 0.615385\n",
      "Iteration 28, loss = 0.84306559\n",
      "Validation score: 0.641026\n",
      "Iteration 29, loss = 0.83083098\n",
      "Validation score: 0.615385\n",
      "Iteration 30, loss = 0.81896377\n",
      "Validation score: 0.615385\n",
      "Iteration 31, loss = 0.80585617\n",
      "Validation score: 0.641026\n",
      "Iteration 32, loss = 0.79237735\n",
      "Validation score: 0.641026\n",
      "Iteration 33, loss = 0.78146182\n",
      "Validation score: 0.615385\n",
      "Iteration 34, loss = 0.77267453\n",
      "Validation score: 0.615385\n",
      "Iteration 35, loss = 0.75867753\n",
      "Validation score: 0.589744\n",
      "Iteration 36, loss = 0.74628120\n",
      "Validation score: 0.564103\n",
      "Iteration 37, loss = 0.73593135\n",
      "Validation score: 0.564103\n",
      "Iteration 38, loss = 0.72494007\n",
      "Validation score: 0.564103\n",
      "Iteration 39, loss = 0.71098164\n",
      "Validation score: 0.564103\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.13251211\n",
      "Validation score: 0.153846\n",
      "Iteration 2, loss = 2.30337636\n",
      "Validation score: 0.256410\n",
      "Iteration 3, loss = 1.89092703\n",
      "Validation score: 0.333333\n",
      "Iteration 4, loss = 1.69177974\n",
      "Validation score: 0.410256\n",
      "Iteration 5, loss = 1.59687907\n",
      "Validation score: 0.333333\n",
      "Iteration 6, loss = 1.56687570\n",
      "Validation score: 0.358974\n",
      "Iteration 7, loss = 1.50993743\n",
      "Validation score: 0.358974\n",
      "Iteration 8, loss = 1.43716032\n",
      "Validation score: 0.358974\n",
      "Iteration 9, loss = 1.37109452\n",
      "Validation score: 0.410256\n",
      "Iteration 10, loss = 1.31816049\n",
      "Validation score: 0.410256\n",
      "Iteration 11, loss = 1.26439326\n",
      "Validation score: 0.384615\n",
      "Iteration 12, loss = 1.21383257\n",
      "Validation score: 0.333333\n",
      "Iteration 13, loss = 1.17928274\n",
      "Validation score: 0.333333\n",
      "Iteration 14, loss = 1.14261957\n",
      "Validation score: 0.333333\n",
      "Iteration 15, loss = 1.11647349\n",
      "Validation score: 0.333333\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.20890199\n",
      "Validation score: 0.384615\n",
      "Iteration 2, loss = 1.82083762\n",
      "Validation score: 0.384615\n",
      "Iteration 3, loss = 1.64364761\n",
      "Validation score: 0.410256\n",
      "Iteration 4, loss = 1.51710164\n",
      "Validation score: 0.435897\n",
      "Iteration 5, loss = 1.42407756\n",
      "Validation score: 0.461538\n",
      "Iteration 6, loss = 1.35501291\n",
      "Validation score: 0.538462\n",
      "Iteration 7, loss = 1.29947354\n",
      "Validation score: 0.487179\n",
      "Iteration 8, loss = 1.25614230\n",
      "Validation score: 0.461538\n",
      "Iteration 9, loss = 1.21983704\n",
      "Validation score: 0.512821\n",
      "Iteration 10, loss = 1.18221896\n",
      "Validation score: 0.461538\n",
      "Iteration 11, loss = 1.14914713\n",
      "Validation score: 0.461538\n",
      "Iteration 12, loss = 1.11555186\n",
      "Validation score: 0.461538\n",
      "Iteration 13, loss = 1.08766230\n",
      "Validation score: 0.461538\n",
      "Iteration 14, loss = 1.05949409\n",
      "Validation score: 0.461538\n",
      "Iteration 15, loss = 1.03898800\n",
      "Validation score: 0.487179\n",
      "Iteration 16, loss = 1.01772002\n",
      "Validation score: 0.564103\n",
      "Iteration 17, loss = 0.99262220\n",
      "Validation score: 0.564103\n",
      "Iteration 18, loss = 0.97312063\n",
      "Validation score: 0.564103\n",
      "Iteration 19, loss = 0.94814388\n",
      "Validation score: 0.564103\n",
      "Iteration 20, loss = 0.93293170\n",
      "Validation score: 0.589744\n",
      "Iteration 21, loss = 0.91540091\n",
      "Validation score: 0.589744\n",
      "Iteration 22, loss = 0.89331411\n",
      "Validation score: 0.589744\n",
      "Iteration 23, loss = 0.87466642\n",
      "Validation score: 0.564103\n",
      "Iteration 24, loss = 0.86098433\n",
      "Validation score: 0.589744\n",
      "Iteration 25, loss = 0.84400382\n",
      "Validation score: 0.615385\n",
      "Iteration 26, loss = 0.82506941\n",
      "Validation score: 0.564103\n",
      "Iteration 27, loss = 0.80885096\n",
      "Validation score: 0.564103\n",
      "Iteration 28, loss = 0.79569128\n",
      "Validation score: 0.615385\n",
      "Iteration 29, loss = 0.77930185\n",
      "Validation score: 0.615385\n",
      "Iteration 30, loss = 0.76571225\n",
      "Validation score: 0.641026\n",
      "Iteration 31, loss = 0.74968039\n",
      "Validation score: 0.615385\n",
      "Iteration 32, loss = 0.73836710\n",
      "Validation score: 0.589744\n",
      "Iteration 33, loss = 0.72279734\n",
      "Validation score: 0.589744\n",
      "Iteration 34, loss = 0.70837030\n",
      "Validation score: 0.641026\n",
      "Iteration 35, loss = 0.69771654\n",
      "Validation score: 0.641026\n",
      "Iteration 36, loss = 0.68621311\n",
      "Validation score: 0.666667\n",
      "Iteration 37, loss = 0.67224110\n",
      "Validation score: 0.692308\n",
      "Iteration 38, loss = 0.65894661\n",
      "Validation score: 0.666667\n",
      "Iteration 39, loss = 0.65028816\n",
      "Validation score: 0.692308\n",
      "Iteration 40, loss = 0.63959803\n",
      "Validation score: 0.717949\n",
      "Iteration 41, loss = 0.62836551\n",
      "Validation score: 0.692308\n",
      "Iteration 42, loss = 0.61518249\n",
      "Validation score: 0.641026\n",
      "Iteration 43, loss = 0.60705214\n",
      "Validation score: 0.615385\n",
      "Iteration 44, loss = 0.59424844\n",
      "Validation score: 0.641026\n",
      "Iteration 45, loss = 0.58244206\n",
      "Validation score: 0.615385\n",
      "Iteration 46, loss = 0.57413673\n",
      "Validation score: 0.615385\n",
      "Iteration 47, loss = 0.56614264\n",
      "Validation score: 0.615385\n",
      "Iteration 48, loss = 0.55578654\n",
      "Validation score: 0.615385\n",
      "Iteration 49, loss = 0.54417336\n",
      "Validation score: 0.641026\n",
      "Iteration 50, loss = 0.53295850\n",
      "Validation score: 0.641026\n",
      "Iteration 51, loss = 0.52687152\n",
      "Validation score: 0.641026\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.74905682\n",
      "Validation score: 0.128205\n",
      "Iteration 2, loss = 2.04184140\n",
      "Validation score: 0.076923\n",
      "Iteration 3, loss = 1.68549200\n",
      "Validation score: 0.358974\n",
      "Iteration 4, loss = 1.55549231\n",
      "Validation score: 0.435897\n",
      "Iteration 5, loss = 1.49520376\n",
      "Validation score: 0.461538\n",
      "Iteration 6, loss = 1.43258258\n",
      "Validation score: 0.487179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.35426658\n",
      "Validation score: 0.538462\n",
      "Iteration 8, loss = 1.28366174\n",
      "Validation score: 0.512821\n",
      "Iteration 9, loss = 1.23385614\n",
      "Validation score: 0.487179\n",
      "Iteration 10, loss = 1.19962913\n",
      "Validation score: 0.461538\n",
      "Iteration 11, loss = 1.17177998\n",
      "Validation score: 0.461538\n",
      "Iteration 12, loss = 1.13879012\n",
      "Validation score: 0.461538\n",
      "Iteration 13, loss = 1.10811017\n",
      "Validation score: 0.487179\n",
      "Iteration 14, loss = 1.08001413\n",
      "Validation score: 0.538462\n",
      "Iteration 15, loss = 1.04997800\n",
      "Validation score: 0.538462\n",
      "Iteration 16, loss = 1.02356363\n",
      "Validation score: 0.564103\n",
      "Iteration 17, loss = 1.00050186\n",
      "Validation score: 0.538462\n",
      "Iteration 18, loss = 0.98179978\n",
      "Validation score: 0.538462\n",
      "Iteration 19, loss = 0.96249960\n",
      "Validation score: 0.538462\n",
      "Iteration 20, loss = 0.94054097\n",
      "Validation score: 0.512821\n",
      "Iteration 21, loss = 0.92079572\n",
      "Validation score: 0.512821\n",
      "Iteration 22, loss = 0.90362527\n",
      "Validation score: 0.512821\n",
      "Iteration 23, loss = 0.88917039\n",
      "Validation score: 0.512821\n",
      "Iteration 24, loss = 0.87429800\n",
      "Validation score: 0.512821\n",
      "Iteration 25, loss = 0.85763652\n",
      "Validation score: 0.538462\n",
      "Iteration 26, loss = 0.84213141\n",
      "Validation score: 0.564103\n",
      "Iteration 27, loss = 0.83026009\n",
      "Validation score: 0.538462\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.61631524\n",
      "Validation score: 0.410256\n",
      "Iteration 2, loss = 2.02457393\n",
      "Validation score: 0.512821\n",
      "Iteration 3, loss = 1.76480179\n",
      "Validation score: 0.461538\n",
      "Iteration 4, loss = 1.60878075\n",
      "Validation score: 0.461538\n",
      "Iteration 5, loss = 1.49112549\n",
      "Validation score: 0.461538\n",
      "Iteration 6, loss = 1.39517783\n",
      "Validation score: 0.461538\n",
      "Iteration 7, loss = 1.33977243\n",
      "Validation score: 0.487179\n",
      "Iteration 8, loss = 1.28705360\n",
      "Validation score: 0.512821\n",
      "Iteration 9, loss = 1.23628776\n",
      "Validation score: 0.512821\n",
      "Iteration 10, loss = 1.18996546\n",
      "Validation score: 0.512821\n",
      "Iteration 11, loss = 1.15347675\n",
      "Validation score: 0.512821\n",
      "Iteration 12, loss = 1.12353153\n",
      "Validation score: 0.512821\n",
      "Iteration 13, loss = 1.09107418\n",
      "Validation score: 0.487179\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.58595843\n",
      "Validation score: 0.256410\n",
      "Iteration 2, loss = 1.89223098\n",
      "Validation score: 0.435897\n",
      "Iteration 3, loss = 1.69900299\n",
      "Validation score: 0.410256\n",
      "Iteration 4, loss = 1.62160914\n",
      "Validation score: 0.461538\n",
      "Iteration 5, loss = 1.55668392\n",
      "Validation score: 0.461538\n",
      "Iteration 6, loss = 1.47231851\n",
      "Validation score: 0.487179\n",
      "Iteration 7, loss = 1.39658380\n",
      "Validation score: 0.487179\n",
      "Iteration 8, loss = 1.33899754\n",
      "Validation score: 0.487179\n",
      "Iteration 9, loss = 1.29137822\n",
      "Validation score: 0.487179\n",
      "Iteration 10, loss = 1.24043555\n",
      "Validation score: 0.538462\n",
      "Iteration 11, loss = 1.19367575\n",
      "Validation score: 0.538462\n",
      "Iteration 12, loss = 1.15882765\n",
      "Validation score: 0.512821\n",
      "Iteration 13, loss = 1.12479458\n",
      "Validation score: 0.512821\n",
      "Iteration 14, loss = 1.08955252\n",
      "Validation score: 0.512821\n",
      "Iteration 15, loss = 1.05869807\n",
      "Validation score: 0.512821\n",
      "Iteration 16, loss = 1.02973610\n",
      "Validation score: 0.538462\n",
      "Iteration 17, loss = 1.00308375\n",
      "Validation score: 0.538462\n",
      "Iteration 18, loss = 0.97801748\n",
      "Validation score: 0.487179\n",
      "Iteration 19, loss = 0.95331172\n",
      "Validation score: 0.487179\n",
      "Iteration 20, loss = 0.93097688\n",
      "Validation score: 0.487179\n",
      "Iteration 21, loss = 0.91303603\n",
      "Validation score: 0.487179\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.48322106\n",
      "Validation score: 0.275000\n",
      "Iteration 2, loss = 1.84232692\n",
      "Validation score: 0.275000\n",
      "Iteration 3, loss = 1.62527440\n",
      "Validation score: 0.225000\n",
      "Iteration 4, loss = 1.55693423\n",
      "Validation score: 0.275000\n",
      "Iteration 5, loss = 1.46769886\n",
      "Validation score: 0.325000\n",
      "Iteration 6, loss = 1.36485515\n",
      "Validation score: 0.400000\n",
      "Iteration 7, loss = 1.29018929\n",
      "Validation score: 0.450000\n",
      "Iteration 8, loss = 1.24912921\n",
      "Validation score: 0.425000\n",
      "Iteration 9, loss = 1.20532109\n",
      "Validation score: 0.500000\n",
      "Iteration 10, loss = 1.16370291\n",
      "Validation score: 0.475000\n",
      "Iteration 11, loss = 1.13178601\n",
      "Validation score: 0.475000\n",
      "Iteration 12, loss = 1.09914632\n",
      "Validation score: 0.475000\n",
      "Iteration 13, loss = 1.06706457\n",
      "Validation score: 0.500000\n",
      "Iteration 14, loss = 1.04111327\n",
      "Validation score: 0.500000\n",
      "Iteration 15, loss = 1.01469613\n",
      "Validation score: 0.500000\n",
      "Iteration 16, loss = 0.99078005\n",
      "Validation score: 0.500000\n",
      "Iteration 17, loss = 0.96868444\n",
      "Validation score: 0.500000\n",
      "Iteration 18, loss = 0.94843233\n",
      "Validation score: 0.500000\n",
      "Iteration 19, loss = 0.92510679\n",
      "Validation score: 0.500000\n",
      "Iteration 20, loss = 0.90455921\n",
      "Validation score: 0.500000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.20288960\n",
      "Validation score: 0.250000\n",
      "Iteration 2, loss = 1.80600372\n",
      "Validation score: 0.250000\n",
      "Iteration 3, loss = 1.59945626\n",
      "Validation score: 0.250000\n",
      "Iteration 4, loss = 1.49037461\n",
      "Validation score: 0.225000\n",
      "Iteration 5, loss = 1.40724067\n",
      "Validation score: 0.350000\n",
      "Iteration 6, loss = 1.33343060\n",
      "Validation score: 0.400000\n",
      "Iteration 7, loss = 1.27508469\n",
      "Validation score: 0.350000\n",
      "Iteration 8, loss = 1.22879251\n",
      "Validation score: 0.350000\n",
      "Iteration 9, loss = 1.19030848\n",
      "Validation score: 0.350000\n",
      "Iteration 10, loss = 1.15162893\n",
      "Validation score: 0.375000\n",
      "Iteration 11, loss = 1.11701201\n",
      "Validation score: 0.375000\n",
      "Iteration 12, loss = 1.08270400\n",
      "Validation score: 0.375000\n",
      "Iteration 13, loss = 1.05222641\n",
      "Validation score: 0.375000\n",
      "Iteration 14, loss = 1.02459493\n",
      "Validation score: 0.425000\n",
      "Iteration 15, loss = 0.99978003\n",
      "Validation score: 0.450000\n",
      "Iteration 16, loss = 0.97891591\n",
      "Validation score: 0.425000\n",
      "Iteration 17, loss = 0.95260871\n",
      "Validation score: 0.425000\n",
      "Iteration 18, loss = 0.92767210\n",
      "Validation score: 0.400000\n",
      "Iteration 19, loss = 0.90771413\n",
      "Validation score: 0.400000\n",
      "Iteration 20, loss = 0.88918309\n",
      "Validation score: 0.375000\n",
      "Iteration 21, loss = 0.87136408\n",
      "Validation score: 0.375000\n",
      "Iteration 22, loss = 0.85241789\n",
      "Validation score: 0.400000\n",
      "Iteration 23, loss = 0.83486581\n",
      "Validation score: 0.375000\n",
      "Iteration 24, loss = 0.81819418\n",
      "Validation score: 0.375000\n",
      "Iteration 25, loss = 0.80171382\n",
      "Validation score: 0.400000\n",
      "Iteration 26, loss = 0.78581808\n",
      "Validation score: 0.375000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.64454979\n",
      "Validation score: 0.250000\n",
      "Iteration 2, loss = 2.10394436\n",
      "Validation score: 0.250000\n",
      "Iteration 3, loss = 1.83443585\n",
      "Validation score: 0.325000\n",
      "Iteration 4, loss = 1.61964575\n",
      "Validation score: 0.325000\n",
      "Iteration 5, loss = 1.45098709\n",
      "Validation score: 0.400000\n",
      "Iteration 6, loss = 1.36072511\n",
      "Validation score: 0.400000\n",
      "Iteration 7, loss = 1.32004539\n",
      "Validation score: 0.425000\n",
      "Iteration 8, loss = 1.27036827\n",
      "Validation score: 0.500000\n",
      "Iteration 9, loss = 1.20505259\n",
      "Validation score: 0.550000\n",
      "Iteration 10, loss = 1.15416445\n",
      "Validation score: 0.525000\n",
      "Iteration 11, loss = 1.11242289\n",
      "Validation score: 0.550000\n",
      "Iteration 12, loss = 1.07541536\n",
      "Validation score: 0.550000\n",
      "Iteration 13, loss = 1.04655599\n",
      "Validation score: 0.575000\n",
      "Iteration 14, loss = 1.01810490\n",
      "Validation score: 0.575000\n",
      "Iteration 15, loss = 0.98807083\n",
      "Validation score: 0.600000\n",
      "Iteration 16, loss = 0.96578371\n",
      "Validation score: 0.550000\n",
      "Iteration 17, loss = 0.93884594\n",
      "Validation score: 0.600000\n",
      "Iteration 18, loss = 0.91619702\n",
      "Validation score: 0.575000\n",
      "Iteration 19, loss = 0.89164636\n",
      "Validation score: 0.575000\n",
      "Iteration 20, loss = 0.87039521\n",
      "Validation score: 0.625000\n",
      "Iteration 21, loss = 0.84664781\n",
      "Validation score: 0.625000\n",
      "Iteration 22, loss = 0.82880360\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.81301066\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.79519266\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.77796410\n",
      "Validation score: 0.675000\n",
      "Iteration 26, loss = 0.76104585\n",
      "Validation score: 0.675000\n",
      "Iteration 27, loss = 0.74617330\n",
      "Validation score: 0.650000\n",
      "Iteration 28, loss = 0.73310819\n",
      "Validation score: 0.650000\n",
      "Iteration 29, loss = 0.72098581\n",
      "Validation score: 0.675000\n",
      "Iteration 30, loss = 0.70695744\n",
      "Validation score: 0.675000\n",
      "Iteration 31, loss = 0.69273761\n",
      "Validation score: 0.675000\n",
      "Iteration 32, loss = 0.67886485\n",
      "Validation score: 0.675000\n",
      "Iteration 33, loss = 0.66858888\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "cvresults=cross_validate(model, X_new_train, Y_new_train, cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.4320755 , 0.35765624, 0.55365205, 0.61515546, 0.5762589 ,\n",
       "        0.92611194, 0.48223138, 1.46949816, 1.9373188 , 1.06947446]),\n",
       " 'score_time': array([0.00149727, 0.00137639, 0.00135875, 0.00134945, 0.0013845 ,\n",
       "        0.00153232, 0.00351739, 0.00130177, 0.00131512, 0.00193214]),\n",
       " 'test_score': array([0.36956522, 0.54347826, 0.43478261, 0.42222222, 0.44444444,\n",
       "        0.39534884, 0.33333333, 0.56097561, 0.48717949, 0.51282051]),\n",
       " 'train_score': array([0.61917098, 0.5984456 , 0.5984456 , 0.63049096, 0.65116279,\n",
       "        0.67609254, 0.56923077, 0.84398977, 0.87022901, 0.81933842])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.57156231\n",
      "Validation score: 0.272727\n",
      "Iteration 2, loss = 1.86932320\n",
      "Validation score: 0.409091\n",
      "Iteration 3, loss = 1.65059117\n",
      "Validation score: 0.409091\n",
      "Iteration 4, loss = 1.54961514\n",
      "Validation score: 0.431818\n",
      "Iteration 5, loss = 1.48462328\n",
      "Validation score: 0.409091\n",
      "Iteration 6, loss = 1.41197149\n",
      "Validation score: 0.454545\n",
      "Iteration 7, loss = 1.34237858\n",
      "Validation score: 0.477273\n",
      "Iteration 8, loss = 1.28773107\n",
      "Validation score: 0.477273\n",
      "Iteration 9, loss = 1.24402541\n",
      "Validation score: 0.477273\n",
      "Iteration 10, loss = 1.20560625\n",
      "Validation score: 0.477273\n",
      "Iteration 11, loss = 1.16514095\n",
      "Validation score: 0.477273\n",
      "Iteration 12, loss = 1.12532120\n",
      "Validation score: 0.545455\n",
      "Iteration 13, loss = 1.09291710\n",
      "Validation score: 0.522727\n",
      "Iteration 14, loss = 1.06291669\n",
      "Validation score: 0.590909\n",
      "Iteration 15, loss = 1.03181661\n",
      "Validation score: 0.568182\n",
      "Iteration 16, loss = 1.00053967\n",
      "Validation score: 0.568182\n",
      "Iteration 17, loss = 0.97318707\n",
      "Validation score: 0.568182\n",
      "Iteration 18, loss = 0.94772422\n",
      "Validation score: 0.568182\n",
      "Iteration 19, loss = 0.92257610\n",
      "Validation score: 0.522727\n",
      "Iteration 20, loss = 0.90145099\n",
      "Validation score: 0.590909\n",
      "Iteration 21, loss = 0.87962235\n",
      "Validation score: 0.636364\n",
      "Iteration 22, loss = 0.86012293\n",
      "Validation score: 0.636364\n",
      "Iteration 23, loss = 0.83941748\n",
      "Validation score: 0.636364\n",
      "Iteration 24, loss = 0.82216358\n",
      "Validation score: 0.613636\n",
      "Iteration 25, loss = 0.80561580\n",
      "Validation score: 0.613636\n",
      "Iteration 26, loss = 0.78905811\n",
      "Validation score: 0.613636\n",
      "Iteration 27, loss = 0.77078809\n",
      "Validation score: 0.613636\n",
      "Iteration 28, loss = 0.75735798\n",
      "Validation score: 0.613636\n",
      "Iteration 29, loss = 0.74356813\n",
      "Validation score: 0.613636\n",
      "Iteration 30, loss = 0.72731880\n",
      "Validation score: 0.590909\n",
      "Iteration 31, loss = 0.71418393\n",
      "Validation score: 0.636364\n",
      "Iteration 32, loss = 0.70219058\n",
      "Validation score: 0.636364\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.01, batch_size=264, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_new_train, Y_new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_true=Y_new_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred,Y_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1,  0,  0,  0,  0,  2],\n",
       "       [ 0,  2,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  1,  2],\n",
       "       [ 0,  0,  0,  2,  0,  0,  1],\n",
       "       [ 1,  3,  0,  0, 13,  6,  0],\n",
       "       [ 0,  1,  0,  0,  1,  6,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
